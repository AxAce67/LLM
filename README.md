# AI Factory Engine (LLM Builder)

ゼロから構築する分散型の大規模言語モデル（LLM）データ収集・学習・推論プラットフォームです。
Webクローラーが自動でデータを収集し、親機がトークナイズとトランスフォーマーモデルの継続学習を行います。すべてはモダンなWebダッシュボードから監視・制御可能です。

## 1. これからの使い方（運用フロー）

本システムは、**「起動して放置する」** タイプのバックグラウンドアプリケーション（サーバーアプリ）です。

1. **システムの起動**: クローラーと学習エンジンを「Ignite(起動)」します。
2. **データの蓄積**: 時間が経つにつれて「Corpus Storage」の数値が増え、独自の知識データがDBに蓄積されていきます。
3. **継続的な学習**: 親機（Master）が定期的に集めたデータを学習し、「Neural Net Training」のEpoch（世代）が進み、Loss（誤差）が下がっていきます。数日〜数週間稼働させ続けることで、AIが賢くなっていきます。
4. **テスト推論**: ダッシュボードの「AI Chat Inference」タブで、プロンプトを入力してAIの成長度合い（知能）をテストします。

## 2. 起動方法とアプリ化について

システムを簡単に起動・デプロイできるように、すでに**Bash化（シェルスクリプト化）およびDocker化**が完了しています。
デスクトップアプリ（.exeや.app）というよりも、サーバーやPCのバックグラウンドで24時間動き続ける「Webサービス・デーモン」として設計されています。

**◆ ローカル開発・確認用（現在行っている方法）**
```bash
source venv/bin/activate
python3 app.py
```
-> `http://localhost:8000` にアクセス

**◆ 完全自動デプロイ・永続化用（インストーラー兼アプリ化）**
付属の `setup.sh` を実行するだけで、必要な環境の構築からDockerによるバックグラウンド起動（PCを閉じても裏で動き続ける状態）まで全自動で行われます。
```bash
chmod +x setup.sh
./setup.sh
```
※ インストール時にマスターパスワード (`Aki5429570607`) がかかっているため、第三者に不正実行されるのを防ぎます。

## 3. 今後のアップデート・開発ロードマップ

ここから先、さらにシステムを強化するための「次なる開発ステップ」のアイディアです。

### 段階 1: モデルの知能と実用性の向上
- **モデルの大型化**: `transformer.py` のレイヤー数やEmbeddingの次元数を増やし、より賢いモデル構成に変更する。
- **RAG（検索拡張生成）の導入**: 実際のAIチャット画面で、AIが回答を作る前にSupabaseのDBから関連するクロール済み文章を検索してきて、それをカンペとして回答させる仕組み（より正確な知識を答えられるようになります）。

### 段階 2: クラウドでの本格運用と分散処理
- **クラウドサーバーへの親機設置**: AWSやGoogle Cloudなどに親機（Master）をデプロイし、24時間365日高速に学習し続ける本格的なサーバーを構築。
- **複数マシンの接続**: 余っている古いPCやノートパソコンで `./setup.sh` を実行し「Worker（子機）」としてセットアップ。ネットワーク越しに親機へデータを送り続ける強力な「Swarm（群れ）」を作ります。

### 段階 3: アプリケーションへの組み込み
- 今アクセスしているAPI（`/api/generate` など）を利用して、独自のiOS/Androidアプリや、LINEボットなどを作成し、裏側の脳みそとしてこの「AI Factory Engine」を連携させる。

---
*Created by the Advanced Agentic Coding Assistant.*
